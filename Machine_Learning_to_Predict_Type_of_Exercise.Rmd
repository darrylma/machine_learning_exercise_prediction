---
title: "Machine Learning to Predict Type of Exercise"
output: 
  html_document:
    keep_md: true
---
by Darryl Ma

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.path = "./figure/")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(include = TRUE)

library(lattice)
library(ggplot2)
library(caret)
library(rattle)
library(e1071)
library(randomForest)
library(gbm)
```

## Executive Summary

We set out to create prediction model that would be able to predict if a barbell lift was being performed properly given measurements from accelerometers placed at various parts of the subject's body. We managed to create a random forest model that achieved 100% accruacy on our validation and testing sets. Additionally, we determined that in order to perform a barbell lift correctly, it is essential that the subject maintain his/her hips in the proper position as well as complete the full forearm motion. 

## Introduction

The goal of this project is to predict the manner in which a subject performed barbell lifts based on input from accelerometers on the belt, forearm, arm, and dumbell. Six participants of age between 20-28 were asked to perform barbell lifts correctly and incorrectly in 5 different ways:

1. Class A: exactly according to the specification
2. Class B: throwing the elbows to the front
3. Class C: lifting the dumbbell only halfway 
4. Class D: lowering the dumbbell only halfway 
5. Class E: throwing the hips to the front

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. The datasets provided contain various quantitative measurements as each of these participants performed different types of barbell lifts. The aim is to categorize/predict how well an activity was performed by the wearer based on these measurements. 

## Loading Data

Two datasets were provided, one training set and one testing set. The code below downloads and loads the datasets into R:

```{r}
training <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), 
                    header = TRUE, na.strings = c("NA", ""))
testing <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), 
                    header = TRUE, na.strings = c("NA", ""))
```

The traing set contains `r dim(training)[1]` observations and `r dim(training)[2]` variables, and the testing set contains `r dim(testing)[1]` observations and `r dim(testing)[2]` variables. 

```{r}
str(training)
```

A quick glance at the list of variables below show that a lot of the variables have NA values. Therefore our first objective is to remove any unneccesary variables that will not have an impact in classification of the type of barbell lift.

## Cleaning the Data

The first is to select variables where there are no NA values:

```{r}
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]
```

This reduces the number of variables to `r dim(training)[2]` and `r dim(testing)[2]` in the training and testing set, respectively. 

```{r}
training <- training[, -c(1:7)]
testing <- testing[, -c(1:7)]
```

From the list of variables, we also see that they first 7 variables: X, username, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window and num_window, will have little to do with how we will classify different types of barbell lifts. As such these first 7 variables were removed from the training and testing sets, further reducing th variable count to `r dim(training)[2]` and `r dim(testing)[2]` in the training and testing set, respectively.  

```{r}
str(training)
```

The final list of features above all appear to be possible factors in determining the final output variable, classe.

## Data Splitting

The training dataset was further split into a cross validation dataset to measure the effectiveness of each prediction model

```{r}
set.seed(1234)
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
training <- training[inTrain,]
validation <- training[-inTrain,]
```

## Prediction Models

A few prediction models were chosen to try and solve this classification problem: decision tree, random forest and gradient boosting method.

### Decision Tree

The following code uses the training set to fit a decision tree model, predicts the classe outcome on the validation set, and reports the confusion matrix and accuracy of the prediction model.

```{r}
rpartFit <- train(classe ~ ., data=training, method="rpart")
rpartPred <- predict(rpartFit, validation)
confusionMatrix(rpartPred, validation$classe)$table
confusionMatrix(rpartPred, validation$classe)$overall[1]
fancyRpartPlot(rpartFit$finalModel)
```

From the output above, we see that the decision tree does not accurately predict the outcome, classe, very well only achieving 50.4% accuracy. The confusion matrix further shows us that this model was particularly very poor at classifying class D, which is corroborated by the dendrogram, where there is no node that classifies an observation as class D. 

### Random Forest

The following code uses the training set to fit a random forest model, predicts the classe outcome on the validation set, and reports the confusion matrix and accuracy of the prediction model.

```{r}
rfFit <- train(classe ~ ., data=training, method="rf")
rfPred <- predict(rfFit, validation)
confusionMatrix(rfPred, validation$classe)$table
confusionMatrix(rfPred, validation$classe)$overall[1]
```

From the output above, we see that the random forest accurately predicts the outcome, classe, very well, achieving 100% accuracy on the validation set. The only drawback was the computational time required to fit this model.

### Gradient Boost Model

The following code uses the training set to fit a gradient boost model, predicts the classe outcome on the validation set, and reports the confusion matrix and accuracy of the prediction model.

```{r}
gbmFit <- train(classe ~ ., data=training, method="gbm", verbose=FALSE)
gbmPred <- predict(gbmFit, validation)
confusionMatrix(gbmPred, validation$classe)$table
confusionMatrix(gbmPred, validation$classe)$overall[1]
```

From the output above, we see that the gradient boost model accurately predicts the outcome, classe, very well, achieving 97.6% accuracy on the validation set. This model achieved relatively high standards of accuracy with better processing time compared to the random forest. Therefore if processing time were an issue, this model may be preferred over the random forest

## Most Influential Variables

```{r}
imp <- data.frame(varImp(rfFit)[1])
top_ten_imp <- rownames(imp)[order(imp$Overall, decreasing=TRUE)[1:10]]
top_ten_imp
avg_by_classe <- aggregate(. ~ classe, training, mean)
avg_by_classe[,c("classe", top_ten_imp[1:3])]
```

The top 10 variables that influenced the random forest model in determining the classe outcome are printed above. As you can see roll_belt, pitch_forearm, and yaw_belt were the top 3 most influenctial variables. The image below provides a visual definition of pitch, yaw and roll, but in general we probably can conclude that being able to perform a barbell lift correctly has a lot to do with maintaining your hips in the proper position as well as making sure you completes the full forearm motion. More specifically, when performing a barbell lift, you should be aiming for the following roll_belt, pitch_forearm, and yaw_belt values:

- roll_belt: 59.9
- pitch_forearm: -9.9
- yaw_belt: -10.8  

![Pitch, Yaw and Roll](figures/pitch_raw_roll.png)

## Conclusion

```{r}
testPred <- predict(rfFit, testing)
testPred
```

Of all the models, we found that the random forest achieved the highest accuracy, 100%. The accuracies achieved by the other models are listed below:

1. Decision Tree: 50.4%
2. Gradient Boost Model: 97.6%
3. Random Forest: 100%

When the random forest model was used to predict the classe outcome for the testing set, it again achieved 100% accuracy, predicting the classe outcome correctly for all 20 observations. Additionally, we determined that in order to perform a barbell lift correctly, it is essential that the subject maintain his/her hips in the proper position as well as complete the full forearm motion.    

